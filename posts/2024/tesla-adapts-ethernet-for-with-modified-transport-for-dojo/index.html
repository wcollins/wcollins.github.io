<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Tesla Adapts Ethernet with Modified Transport Layer for Dojo - Blog</title><meta name=Description content="Exploring the disruptive world of cloud tech"><meta property="og:title" content="Tesla Adapts Ethernet with Modified Transport Layer for Dojo"><meta property="og:description" content="The foundation of high-performance computing that powers artificial intelligence lies not just in powerful GPUs, but in the intricate web of connections between them. As models grow exponentially in size and complexity, the networking infrastructure that facilitates their training has become a critical bottleneck. This has sparked a fascinating race to develop networking solutions tailored for AI-centric workloads, with tech giants like NVIDIA who are on an infrastructure trailblazing marathon."><meta property="og:type" content="article"><meta property="og:url" content="http://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/"><meta property="og:image" content="http://wcollins.io/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-05T12:05:44-04:00"><meta property="article:modified_time" content="2024-09-05T12:05:44-04:00"><meta property="og:site_name" content="Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://wcollins.io/"><meta name=twitter:title content="Tesla Adapts Ethernet with Modified Transport Layer for Dojo"><meta name=twitter:description content="The foundation of high-performance computing that powers artificial intelligence lies not just in powerful GPUs, but in the intricate web of connections between them. As models grow exponentially in size and complexity, the networking infrastructure that facilitates their training has become a critical bottleneck. This has sparked a fascinating race to develop networking solutions tailored for AI-centric workloads, with tech giants like NVIDIA who are on an infrastructure trailblazing marathon."><meta name=application-name content="Blog"><meta name=apple-mobile-web-app-title content="Blog"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><meta name=twitter:creator content="@WCollins502"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=http://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/><link rel=prev href=http://wcollins.io/posts/2024/taxing-unrealized-gains/><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/color.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><meta name=google-site-verification content="FSCEdJZD7nAoKk16ak20hRMKNBvXlnHAU0PBBDZy5DU"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Tesla Adapts Ethernet with Modified Transport Layer for Dojo","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"http://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/"},"genre":"posts","keywords":"ai, dojo, networking, infiniBand, rdma, roce, ttpoe, tesla, nvidia, ultraethernet","wordcount":1293,"url":"http://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/","datePublished":"2024-09-05T12:05:44-04:00","dateModified":"2024-09-05T12:05:44-04:00","publisher":{"@type":"Organization","name":"William Collins"},"author":{"@type":"Person","name":"William Collins"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark"),window.theme=e,window.isDark=window.theme!=="light"}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"light"==="light"||"light"==="dark"||"light"==="black"?(setTheme("light"),saveTheme("light")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")],window.switchThemeEventSet=new Set</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=Blog></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/>Home </a><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/talks/>Talks </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/about>About </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=Blog></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/ title>Home</a><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/talks/ title>Talks</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/categories/ title>Categories</a><a class=menu-item href=/about title>About</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto><nav id=TableOfContents><ul><li><a href=#the-lossless-imperative>The Lossless Imperative</a></li><li><a href=#nvidias-mellanox-masterstroke>NVIDIA&rsquo;s Mellanox Masterstroke</a></li><li><a href=#roce-bridging-worlds>RoCE: Bridging Worlds</a></li><li><a href=#how-is-teslas-ttpoe-different>How is Tesla&rsquo;s TTPoE Different?</a><ul><li><a href=#tcp-got-it-right---just-do-it-in-hardware>TCP Got It Right - Just Do It In Hardware</a></li><li><a href=#dumb-nic-and-potential-performance-gains>Dumb-NIC and Potential Performance Gains</a></li></ul></li><li><a href=#ultraethernet-consortium-and-public-offering>UltraEthernet Consortium and Public Offering</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></div><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Tesla Adapts Ethernet with Modified Transport Layer for Dojo</h1><div class=post-meta><div class=post-meta-line><span class=post-author><span class="author fas fa-user-circle fa-fw"></span><a href=/ title=Author rel=author class=author>William Collins</a>
</span>&nbsp;<span class=post-category>included in </span>&nbsp;<span class=post-category>categories <a href=/categories/ai/><i class="far fa-folder fa-fw"></i>ai</a>&nbsp;<a href=/categories/data-center/><i class="far fa-folder fa-fw"></i>data-center</a>&nbsp;<a href=/categories/supercomputing/><i class="far fa-folder fa-fw"></i>supercomputing</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="5 September 2024">5 September 2024</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime="5 September 2024">5 September 2024</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1293 words&nbsp;<i class="far fa-clock fa-fw"></i>&nbsp;7 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#the-lossless-imperative>The Lossless Imperative</a></li><li><a href=#nvidias-mellanox-masterstroke>NVIDIA&rsquo;s Mellanox Masterstroke</a></li><li><a href=#roce-bridging-worlds>RoCE: Bridging Worlds</a></li><li><a href=#how-is-teslas-ttpoe-different>How is Tesla&rsquo;s TTPoE Different?</a><ul><li><a href=#tcp-got-it-right---just-do-it-in-hardware>TCP Got It Right - Just Do It In Hardware</a></li><li><a href=#dumb-nic-and-potential-performance-gains>Dumb-NIC and Potential Performance Gains</a></li></ul></li><li><a href=#ultraethernet-consortium-and-public-offering>UltraEthernet Consortium and Public Offering</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></div><div class=content id=content><p>The foundation of high-performance computing that powers <em>artificial intelligence</em> lies not just in powerful GPUs, but in the intricate web of connections between them. As models grow exponentially in size and complexity, the networking infrastructure that facilitates their training has become a critical bottleneck. This has sparked a fascinating race to develop networking solutions tailored for AI-centric workloads, with tech giants like <a href=https://www.nvidia.com/en-us/networking/ target=_blank rel="noopener noreferrer">NVIDIA</a> who are on an infrastructure <em>trailblazing</em> marathon.</p><p>In <em>big tech</em>, unique requirements drive cool <em>(and sometimes custom)</em> innovations. Never one to follow the crowd, <a href=https://tesla.com target=_blank rel="noopener noreferrer">Tesla</a> has developed its own networking protocol tailored for AI workloads: TTPoE (Tesla Transport Protocol over Ethernet). As presented at <a href=https://chipsandcheese.com/2024/08/27/teslas-ttpoe-at-hot-chips-2024-replacing-tcp-for-low-latency-applications/ target=_blank rel="noopener noreferrer">Hot Chips 2024</a>, TTPoE takes a fundamentally different approach to the high-performance networking problem. You can find the source material slides <a href=./tesla-ttpoe-slides.pdf rel>here.</a></p><p><figure><a class=lightgallery href=/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/intro.png title=Intro data-thumbnail=/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/intro.png data-sub-html="<h2>Intro</h2><p>Intro</p>"><img loading=lazy src=/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/intro.png srcset="/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/intro.png, /posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/intro.png 1.5x, /posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/intro.png 2x" sizes=auto alt=Intro height=3092 width=6052></a><figcaption class=image-caption>Intro</figcaption></figure></p><h2 id=the-lossless-imperative class=headerLink><a href=#the-lossless-imperative class=header-mark></a>The Lossless Imperative</h2><p>At the heart of this networking revolution is the concept of lossless vs. lossy networks. Traditional Ethernet networks are lossy by nature - packets can be dropped when congestion occurs. While this is acceptable for many applications, AI workloads are exceptionally sensitive to data loss. If a datagram is dropped, GPUs may become idle while waiting to resynchronize. Moreover, GPUs need to be synchronized at the start and end of a run. When a run ends, the processed data often needs to be distributed across GPUs.</p><p>This is where lossless networking protocols like InfiniBand and RoCE <em>(RDMA over Converged Ethernet)</em> enter the picture. These technologies implement flow control mechanisms to prevent packet loss, ensuring reliable data transmission even under heavy load. However, achieving lossless behavior comes with its own set of trade-offs, including increased complexity and potential for congestion spreading.</p><div class="details admonition warning open"><div class="details-summary admonition-title"><i class="icon fas fa-exclamation-triangle fa-fw"></i>Optimizing for Efficiency + ROI<i class="details-icon fas fa-angle-right fa-fw"></i></div><div class=details-content><div class=admonition-content>Can you imagine running <strong>> billion dollars</strong> worth of GPUs and having synchronization issues stemming from packet loss on the network? Talk about a gigantic waste of computational resources. If you are training at this scale, network efficiency becomes massively critical. Ethernet is inherently lossy. Atop Ethernet, protocols like <strong>IP</strong> and <strong>TCP/IP</strong> introduce additional layers where loss can occur <em>(think buffering, queues, etc.)</em></div></div></div><h2 id=nvidias-mellanox-masterstroke class=headerLink><a href=#nvidias-mellanox-masterstroke class=header-mark></a>NVIDIA&rsquo;s Mellanox Masterstroke</h2><p>In 2020, <a href=https://nvidianews.nvidia.com/news/nvidia-completes-acquisition-of-mellanox-creating-major-force-driving-next-gen-data-centers target=_blank rel="noopener noreferrer">NVIDIA completed its $7 billion acquisition of Mellanox</a>, a move that seemed puzzling to some at the time. In retrospect, it was a stroke of genius. Mellanox was the leading provider of InfiniBand and high-performance Ethernet solutions - precisely the technologies needed to unlock the full potential of NVIDIA&rsquo;s GPUs for AI workloads.</p><p>This acquisition gave NVIDIA end-to-end control over the AI computing stack, from GPUs to networking fabric. It allowed them to optimize the entire pipeline, resulting in solutions like the <a href=https://www.nvidia.com/en-us/data-center/dgx-superpod/ target=_blank rel="noopener noreferrer">NVIDIA DGX SuperPOD</a> that can scale to thousands of GPUs with minimal performance loss. The foresight demonstrated in this acquisition has positioned NVIDIA as the dominant force in AI infrastructure. If you want to hear the whole story straight from <em>Jensen Huang</em>, check out <a href=https://www.acquired.fm/episodes/jensen-huang target=_blank rel="noopener noreferrer">this episode of the Acquired Podcast</a>.</p><h2 id=roce-bridging-worlds class=headerLink><a href=#roce-bridging-worlds class=header-mark></a>RoCE: Bridging Worlds</h2><p>While InfiniBand offers unparalleled performance for all your AI workload needs, its proprietary nature and specialized hardware requirements can be a barrier for many organizations. Enter <a href=https://docs.nvidia.com/networking/display/mlnxofedv23070512/rdma+over+converged+ethernet+%28roce%29 target=_blank rel="noopener noreferrer">RoCE (RDMA over Converged Ethernet)</a>, which aims to bring the benefits of RDMA (Remote Direct Memory Access) to standard Ethernet networks.</p><p>RoCE implements many of the same lossless principles as InfiniBand but does so over familiar Ethernet infrastructure. This offers a compelling middle ground - performance approaching that of InfiniBand, but with greater flexibility and potential cost savings. However, achieving truly lossless behavior with RoCE requires careful network configuration and can be challenging to scale in large deployments.</p><div class="details admonition tip open"><div class="details-summary admonition-title"><i class="icon fas fa-lightbulb fa-fw"></i>The Middle Ground<i class="details-icon fas fa-angle-right fa-fw"></i></div><div class=details-content><div class=admonition-content><p>Wait, your whole business model doesn&rsquo;t revolve around <strong>AI/ML</strong>? That sounds like most of the companies out there! This means you are probably seeking a middle ground. This is where RoCE comes into play. Since just about every organization out there already runs on Ethernet powered infrastructure, RoCE offers a path forward without the necessity to completely overhaul your existing network.</p><p>So it doesn&rsquo;t match InfiniBand&rsquo;s peak performance? If the cost saving is substantial, the deployment familiar, and RoCE and traditional ethernet can coexist, then why adopt the complexity of InfiniBand? If you do however require the absolute highest performance and can justify the investment in a specialized network, InfiniBand remains the top choice.</p></div></div></div><h2 id=how-is-teslas-ttpoe-different class=headerLink><a href=#how-is-teslas-ttpoe-different class=header-mark></a>How is Tesla&rsquo;s TTPoE Different?</h2><p>Instead of implementing complex lossless mechanisms, TTPoE adapts Ethernet by replacing TCP with a custom transport layer with the goal of delivering <em>microsecond-scale</em> latency while allowing for simple hardware offload. How does it do this? By simplifying connection handling, removing wait states present in TCP, and taking a more direct approach to congestion control.</p><p><figure><a class=lightgallery href=/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/osi-stack.png title="OSI Stack" data-thumbnail=/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/osi-stack.png data-sub-html="<h2>Dojo OSI Layers</h2><p>OSI Stack</p>"><img loading=lazy src=/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/osi-stack.png srcset="/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/osi-stack.png, /posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/osi-stack.png 1.5x, /posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/osi-stack.png 2x" sizes=auto alt="OSI Stack" height=2129 width=5676></a><figcaption class=image-caption>Dojo OSI Layers</figcaption></figure></p><div class="details admonition note open"><div class="details-summary admonition-title"><i class="icon fas fa-pencil-alt fa-fw"></i>TCP Wait States<i class="details-icon fas fa-angle-right fa-fw"></i></div><div class=details-content><div class=admonition-content>This is an oversimplification, but for those who are not deep in the <em>network engineering</em> discipline, let&rsquo;s try and simplify: TCP wait states happen during the process of establishing or terminating a connection between two devices over a network. When this happens, TCP pauses during the connection process and sequences data packets to ensure ordered delivery - which is why these pauses are necessary. When packet loss occurs, it triggers TCP&rsquo;s recovery mechanisms, leading to more wait states and retransmissions. When dealing with large volume, this problem snowballs quickly.</div></div></div><h3 id=tcp-got-it-right---just-do-it-in-hardware class=headerLink><a href=#tcp-got-it-right---just-do-it-in-hardware class=header-mark></a>TCP Got It Right - Just Do It In Hardware</h3><p><em>TCP Got it right - just do it in hardware</em> is a direct quote from Tesla&rsquo;s presentation and speaks to TTPoE&rsquo;s key differentiator: it&rsquo;s implemented in hardware. Tesla designed a custom MAC <em>(Media Access Control)</em> hardware block that sits between the chip and standard Ethernet hardware. This block, described as acting like a shared cache, handles the TTPoE protocol entirely in hardware, making it transparent to software.</p><p>This aids in the protocol facilitating efficient data transmission across standard Ethernet networks. Unlike lossless RDMA networks that require specialized switches, TTPoE functions over conventional Layer-2 transport. In contrast to both traditional TCP/UDP protocols and lossless RDMA solutions, TTPoE takes a unique approach by anticipating potential packet loss and incorporating built-in retry mechanisms. This design philosophy sets it apart in the landscape of network protocols.</p><h3 id=dumb-nic-and-potential-performance-gains class=headerLink><a href=#dumb-nic-and-potential-performance-gains class=header-mark></a>Dumb-NIC and Potential Performance Gains</h3><p>TTPoE is implemented on what Tesla calls a &ldquo;Dumb-NIC&rdquo; - a cost-effective network interface card designed for commodity driven scale. This approach allows Tesla to efficiently scale the number of host nodes feeding their Dojo supercomputer, which powers their autonomous driving training workloads.</p><p>At Hot Chips 2024, Tesla suggested that TTPoE could offer lower one-way write latency over switches, including NVLink. This claim, if proven in real-world deployments, could have significant implications for the performance of distributed AI training workloads.</p><h2 id=ultraethernet-consortium-and-public-offering class=headerLink><a href=#ultraethernet-consortium-and-public-offering class=header-mark></a>UltraEthernet Consortium and Public Offering</h2><p>Tesla also announced its participation in the <a href=https://ultraethernet.org/ target=_blank rel="noopener noreferrer">UltraEthernet Consortium (UEC)</a>. This step indicates Tesla&rsquo;s intention to promote TTPoE as a potential new standard beyond just their own operations. By offering TTPoE publicly, Tesla is positioning its technology as a possible solution for broader AI and high-performance computing applications. Sharing is caring!</p><h2 id=conclusion class=headerLink><a href=#conclusion class=header-mark></a>Conclusion</h2><p>The emergence of these diverse networking approaches - InfiniBand, RoCE, and TTPoE - highlights a crucial point: there is no one-size-fits-all solution for AI infrastructure or even tech more broadly. Each approach has its strengths and trade-offs, making them suitable for different scenarios.</p><p>InfiniBand remains the gold standard for ultimate performance in controlled environments. RoCE offers a bridge to lossless networking for organizations heavily invested in Ethernet infrastructure. Tesla&rsquo;s TTPoE, while still unproven at scale, demonstrates the potential for new ideas and innovation tailored for specific unique purposes.</p><p>As AI continues to push the boundaries of computing, we can expect further innovations in networking technology. The key takeaway is the importance of aligning infrastructure choices with specific workload requirements and organizational constraints. The future of AI will likely be built not on a single networking standard, but on a diverse ecosystem of solutions, each optimized for particular use cases. Big thanks to <a href=https://www.linkedin.com/in/alumbis/ target=_blank rel="noopener noreferrer">Pete Lumbis</a> for taking the time to peer review!</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 5 September 2024</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-mardown href=/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/index.md target=_blank rel="noopener noreferrer">Read markdown</a></span></div><div class=post-info-share></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/ai/>ai</a>,&nbsp;<a href=/tags/dojo/>dojo</a>,&nbsp;<a href=/tags/networking/>networking</a>,&nbsp;<a href=/tags/infiniband/>infiniBand</a>,&nbsp;<a href=/tags/rdma/>rdma</a>,&nbsp;<a href=/tags/roce/>roce</a>,&nbsp;<a href=/tags/ttpoe/>ttpoe</a>,&nbsp;<a href=/tags/tesla/>tesla</a>,&nbsp;<a href=/tags/nvidia/>nvidia</a>,&nbsp;<a href=/tags/ultraethernet/>ultraethernet</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/2024/taxing-unrealized-gains/ class=prev rel=prev title="The Ripple Effect: Could Taxing Unrealized Gains Stifle Innovation?"><i class="fas fa-angle-left fa-fw"></i>The Ripple Effect: Could Taxing Unrealized Gains Stifle Innovation?</a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2019 - 2024</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank rel="noopener noreferrer">William Collins</a></span></div><div class=footer-line></div><div class=footer-line></div></div></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><div class=assets><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},search:{distance:null,findAllMatches:null,fuseIndexURL:"/index.json",highlightTag:"em",ignoreFieldNorm:null,ignoreLocation:null,isCaseSensitive:null,location:null,maxResultLength:10,minMatchCharLength:null,noResultsFound:"No results found",snippetLength:30,threshold:null,type:"fuse",useExtendedSearch:null}}</script><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/js/theme.min.js defer></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-9QKVT40M3H")</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=G-9QKVT40M3H" async></script></div></body></html>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Rdma - Tag - Blog</title><link>http://wcollins.io/tags/rdma/</link><description>Rdma - Tag - Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 05 Sep 2024 12:05:44 -0400</lastBuildDate><atom:link href="http://wcollins.io/tags/rdma/" rel="self" type="application/rss+xml"/><item><title>Tesla Adapts Ethernet with Modified Transport Layer for Dojo</title><link>http://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/</link><pubDate>Thu, 05 Sep 2024 12:05:44 -0400</pubDate><author><name>William Collins</name></author><guid>http://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/</guid><description>The foundation of high-performance computing that powers artificial intelligence lies not just in powerful GPUs, but in the intricate web of connections between them. As models grow exponentially in size and complexity, the networking infrastructure that facilitates their training has become a critical bottleneck. This has sparked a fascinating race to develop networking solutions tailored for AI-centric workloads, with tech giants like NVIDIA who are on an infrastructure trailblazing marathon.</description></item></channel></rss>
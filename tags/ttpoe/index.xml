<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ttpoe on William Collins</title><link>https://wcollins.io/tags/ttpoe/</link><description>Recent content in Ttpoe on William Collins</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2026 William Collins</copyright><lastBuildDate>Thu, 05 Sep 2024 12:05:44 -0400</lastBuildDate><atom:link href="https://wcollins.io/tags/ttpoe/index.xml" rel="self" type="application/rss+xml"/><item><title>Tesla Adapts Ethernet with Modified Transport Layer for Dojo</title><link>https://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/</link><pubDate>Thu, 05 Sep 2024 12:05:44 -0400</pubDate><guid>https://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/</guid><description>&lt;p&gt;The foundation of high-performance computing that powers &lt;em&gt;artificial intelligence&lt;/em&gt; lies not just in powerful GPUs, but in the intricate web of connections between them. As models grow exponentially in size and complexity, the networking infrastructure that facilitates their training has become a critical bottleneck. This has sparked a fascinating race to develop networking solutions tailored for AI-centric workloads, with tech giants like &lt;a href="https://www.nvidia.com/en-us/networking/" target="_blank" rel="noreferrer"&gt;NVIDIA&lt;/a&gt; who are on an infrastructure &lt;em&gt;trailblazing&lt;/em&gt; marathon.&lt;/p&gt;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://wcollins.io/posts/2024/tesla-adapts-ethernet-for-with-modified-transport-for-dojo/featured.png"/></item></channel></rss>